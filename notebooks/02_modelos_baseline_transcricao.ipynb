{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# ! pip install basic-pitch\n",
    "# ! pip install note-seq\n",
    "# ! pip install tensorflow==2.11.0\n",
    "# ! pip install pretty_midi librosa music21\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function predict_and_save in module basic_pitch.inference:\n",
      "\n",
      "predict_and_save(audio_path_list: Sequence[Union[pathlib.Path, str]], output_directory: Union[pathlib.Path, str], save_midi: bool, sonify_midi: bool, save_model_outputs: bool, save_notes: bool, model_or_model_path: Union[basic_pitch.inference.Model, str, pathlib.Path], onset_threshold: float = 0.5, frame_threshold: float = 0.3, minimum_note_length: float = 127.7, minimum_frequency: Optional[float] = None, maximum_frequency: Optional[float] = None, multiple_pitch_bends: bool = False, melodia_trick: bool = True, debug_file: Optional[pathlib.Path] = None, sonification_samplerate: int = 44100, midi_tempo: float = 120) -> None\n",
      "    Make a prediction and save the results to file.\n",
      "    \n",
      "    Args:\n",
      "        audio_path_list: List of file paths for the audio to run inference on.\n",
      "        output_directory: Directory to output MIDI and all other outputs derived from the model to.\n",
      "        save_midi: True to save midi.\n",
      "        sonify_midi: Whether or not to render audio from the MIDI and output it to a file.\n",
      "        save_model_outputs: True to save contours, onsets and notes from the model prediction.\n",
      "        save_notes: True to save note events.\n",
      "        model_or_model_path: A loaded Model or path to a serialized model to load.\n",
      "        onset_threshold: Minimum energy required for an onset to be considered present.\n",
      "        frame_threshold: Minimum energy requirement for a frame to be considered present.\n",
      "        minimum_note_length: The minimum allowed note length in milliseconds.\n",
      "        minimum_freq: Minimum allowed output frequency, in Hz. If None, all frequencies are used.\n",
      "        maximum_freq: Maximum allowed output frequency, in Hz. If None, all frequencies are used.\n",
      "        multiple_pitch_bends: If True, allow overlapping notes in midi file to have pitch bends.\n",
      "        melodia_trick: Use the melodia post-processing step.\n",
      "        debug_file: An optional path to output debug data to. Useful for testing/verification.\n",
      "        sonification_samplerate: Sample rate for rendering audio from MIDI.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from basic_pitch.inference import predict_and_save\n",
    "help(predict_and_save)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Transcrevendo com basic-pitch...\n",
      "\n",
      "Predicting MIDI for E:\\Projetos\\Melodyscribe\\audios\\one.wav...\n",
      "\n",
      "\n",
      "  Creating midi...\n",
      "  ðŸ’… Saved to E:\\Projetos\\Melodyscribe\\audios\\one_basic_pitch.mid\n",
      "\n",
      "\n",
      "  Creating note events...\n",
      "  ðŸŒ¸ Saved to E:\\Projetos\\Melodyscribe\\audios\\one_basic_pitch.csv\n",
      "ðŸ“„ Convertendo MIDI para MusicXML...\n",
      "âœ… Pronto!\n",
      "- MIDI: E:\\Projetos\\Melodyscribe\\audios\\one_basic_pitch.mid\n",
      "- MusicXML: E:\\Projetos\\Melodyscribe\\audios\\one_basic_pitch.musicxml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from basic_pitch.inference import predict_and_save\n",
    "from basic_pitch import ICASSP_2022_MODEL_PATH\n",
    "from music21 import converter\n",
    "\n",
    "AUDIO_PATH = r\"E:\\Projetos\\Melodyscribe\\audios\\one.wav\"\n",
    "OUTPUT_DIR = os.path.dirname(AUDIO_PATH)\n",
    "\n",
    "print(\"ðŸŽ¯ Transcrevendo com basic-pitch...\")\n",
    "\n",
    "predict_and_save(\n",
    "    [AUDIO_PATH],               # lista de caminhos de Ã¡udio\n",
    "    OUTPUT_DIR,                 # pasta de saÃ­da\n",
    "    True,                       # save_midi\n",
    "    False,                      # sonify_midi\n",
    "    False,                      # save_model_outputs\n",
    "    True,                       # save_notes\n",
    "    ICASSP_2022_MODEL_PATH      # modelo: path oficial\n",
    ")\n",
    "\n",
    "midi_path = AUDIO_PATH.replace('.wav', '_basic_pitch.mid')\n",
    "xml_path = AUDIO_PATH.replace('.wav', '_basic_pitch.musicxml')\n",
    "\n",
    "print(\"ðŸ“„ Convertendo MIDI para MusicXML...\")\n",
    "score = converter.parse(midi_path)\n",
    "score.write(\"musicxml\", fp=xml_path)\n",
    "\n",
    "print(\"âœ… Pronto!\")\n",
    "print(f\"- MIDI: {midi_path}\")\n",
    "print(f\"- MusicXML: {xml_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
